{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesado datos tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"individual_id\": pl.String,\n",
    "    \"abbreviated_name\": pl.Utf8,\n",
    "    \"date\": pl.Datetime,\n",
    "    \"decimal_longitude\": pl.Float64,\n",
    "    \"decimal_latitude\": pl.Float64,\n",
    "    \"longitude_se\": pl.Float64,\n",
    "    \"latitude_se\": pl.Float64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv(\"../../data/foca.csv\", schema=schema)\n",
    "data = data.drop([\"longitude_se\", \"latitude_se\", \"abbreviated_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    data\n",
    "    .with_columns(pl.col(\"date\").dt.year().alias(\"year\"))\n",
    "    .with_columns(pl.col(\"date\").dt.month().alias(\"month\"))\n",
    "    .with_columns(pl.col(\"date\").dt.day().alias(\"day\"))\n",
    "    .with_columns(pl.col(\"date\").dt.hour().alias(\"hour\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consecutive days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_consecutive_days(df):\n",
    "\n",
    "    unique_dates = df.select('date').unique().sort(by='date')['date'].to_list()\n",
    "\n",
    "    # Encontrar la secuencia más larga de días consecutivos\n",
    "    max_streak = 0\n",
    "    current_streak = 1\n",
    "    start_date = unique_dates[0]\n",
    "    best_start, best_end = start_date, start_date\n",
    "    \n",
    "    for i in range(1, len(unique_dates)):\n",
    "        if (unique_dates[i] - unique_dates[i - 1]).days <= 1:\n",
    "            current_streak += 1\n",
    "        else:\n",
    "            if current_streak > max_streak:\n",
    "                max_streak = current_streak\n",
    "                best_start, best_end = start_date, unique_dates[i - 1]\n",
    "            current_streak = 1\n",
    "            start_date = unique_dates[i]\n",
    "    \n",
    "    if current_streak > max_streak:\n",
    "        max_streak = current_streak\n",
    "        best_start, best_end = start_date, unique_dates[-1]\n",
    "    \n",
    "    return max_streak, best_start, best_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_streak, best_start, best_end = longest_consecutive_days(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(pl.col(\"date\") >= best_start).filter(pl.col(\"date\") <= best_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = (\n",
    "    data\n",
    "    .sort(by = \"hour\")\n",
    "    .group_by([\"individual_id\", \"year\", \"month\", \"day\"])\n",
    "    .agg(pl.all().last())\n",
    ")\n",
    "data_processed = data_processed.sort(by=[\"year\", \"month\", \"day\", \"hour\", \"individual_id\"], descending=[False, False, False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radio de la Tierra en km\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return R * c  # Distancia en km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = data_processed.with_columns([\n",
    "    pl.col(\"decimal_latitude\").shift(1).over(\"individual_id\").alias(\"prev_lat\"),\n",
    "    pl.col(\"decimal_longitude\").shift(1).over(\"individual_id\").alias(\"prev_lon\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función de Haversine usando `map`\n",
    "data_processed = data_processed.with_columns(\n",
    "    pl.struct([\"decimal_latitude\", \"decimal_longitude\", \"prev_lat\", \"prev_lon\"]).map_elements(\n",
    "        lambda row: haversine(row[\"prev_lat\"], row[\"prev_lon\"], row[\"decimal_latitude\"], row[\"decimal_longitude\"])\n",
    "        if row[\"prev_lat\"] is not None else None, return_dtype=pl.Float64\n",
    "    ).alias(\"distance_km\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = data_processed.with_columns(\n",
    "    (pl.col(\"decimal_latitude\") - pl.col(\"prev_lat\")).alias(\"delta_lat\"),\n",
    "    (pl.col(\"decimal_longitude\") - pl.col(\"prev_lon\")).alias(\"delta_lon\")\n",
    ")\n",
    "\n",
    "# Calcular el ángulo en radianes y convertirlo a grados\n",
    "data_processed = data_processed.with_columns(\n",
    "    pl.struct([\"delta_lat\", \"delta_lon\"])\n",
    "    .map_elements(lambda d: np.degrees(np.arctan2(d[\"delta_lat\"], d[\"delta_lon\"])) if d[\"delta_lat\"] is not None and d[\"delta_lon\"] is not None else None,\n",
    "                  return_dtype=pl.Float64)\n",
    "    .alias(\"angle_degrees\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Parsear y formatear la fecha para que se pueda concatenar con los datos de Copernicus\n",
    "data_processed = (\n",
    "    data_processed\n",
    "    .with_columns(\n",
    "        pl.col(\"date\").map_elements(\n",
    "            lambda x: datetime.strftime(x, \"%Y-%m-%dT00:00:00\"), \n",
    "            return_dtype=pl.String\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"individual_id\": pl.String,\n",
    "    \"date\": pl.String,\n",
    "    \"decimal_longitude\": pl.Float64,\n",
    "    \"decimal_latitude\": pl.Float64,\n",
    "    \"year\": pl.Int32,\n",
    "    \"month\": pl.Int8,\n",
    "    \"day\": pl.Int8,\n",
    "    \"hour\": pl.Int8,\n",
    "}\n",
    "data = pl.read_csv(\"../../data/foca_procesado.csv\", schema=schema)\n",
    "data = data.drop(\"individual_id\")\n",
    "data.write_csv(\"../../data/datos_foca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed.write_csv(\"../../data/foca_procesado.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
